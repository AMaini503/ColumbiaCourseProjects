{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import copy\n",
    "from time import time\n",
    "import scipy.misc\n",
    "import random\n",
    "\n",
    "t1 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)  # for Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF order [batch, in_height, in_width, in_channels]\n",
    "## opencv,scipy H W K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to load data, DO NOT change these\n",
    "def get_files(folder):\n",
    "    \"\"\"\n",
    "    Given path to folder, returns list of files in it\n",
    "    \"\"\"\n",
    "    filenames = [file for file in glob.glob(folder+'*/*')]\n",
    "    filenames.sort()\n",
    "    return filenames\n",
    "\n",
    "def get_label(filepath, label2id):\n",
    "    \"\"\"\n",
    "    Files are assumed to be labeled as: /path/to/file/999_frog.png\n",
    "    Returns label for a filepath\n",
    "    \"\"\"\n",
    "    tokens = filepath.split('/')\n",
    "    label = tokens[-1].split('_')[1][:-4]\n",
    "    if label in label2id:\n",
    "        return label2id[label]\n",
    "    else:\n",
    "        sys.exit(\"Invalid label: \" + label)\n",
    "        \n",
    "def get_labels(folder, label2id):\n",
    "    \"\"\"\n",
    "    Returns vector of labels extracted from filenames of all files in folder\n",
    "    :param folder: path to data folder\n",
    "    :param label2id: mapping of text labels to numeric ids. (Eg: automobile -> 0)\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    y = []\n",
    "    for f in files:\n",
    "        y.append(get_label(f,label2id))\n",
    "    return np.array(y)\n",
    "\n",
    "\n",
    "def one_hot(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    Converts each label index in y to vector with one_hot encoding\n",
    "    \"\"\"\n",
    "    y_one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    for i in range(y.shape[0]):\n",
    "        y_one_hot[i,y[i]]=1\n",
    "    return y_one_hot.T\n",
    "\n",
    "def get_label_mapping(label_file):\n",
    "    \"\"\"\n",
    "    Returns mappings of label to index and index to label\n",
    "    The input file has list of labels, each on a separate line.\n",
    "    \"\"\"\n",
    "    with open(label_file, 'r') as f:\n",
    "        id2label = f.readlines()\n",
    "        id2label = [l.strip() for l in id2label]\n",
    "    label2id = {}\n",
    "    count = 0\n",
    "    for label in id2label:\n",
    "        label2id[label] = count\n",
    "        count += 1\n",
    "    return id2label, label2id\n",
    "\n",
    "def get_images(folder):\n",
    "    \"\"\"\n",
    "    returns numpy array of all samples in folder\n",
    "    each column is a sample resized to 30x30 and flattened\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    images = []\n",
    "    count = 0\n",
    "    X = np.zeros((len(files),32,32,3))\n",
    "    for f in files:\n",
    "        count += 1\n",
    "        if count % 10000 == 0:\n",
    "            print(\"Loaded {}/{}\".format(count,len(files)))\n",
    "        img_arr = scipy.misc.imread(f)\n",
    "        #img_arr = img_arr.flatten() / 255.0\n",
    "        img_arr = img_arr.astype(float)  #H,W,K\n",
    "        images.append(img_arr)\n",
    "        X[count-1,:,:,:] = img_arr[np.newaxis,:]   #  [batch, in_height, in_width, in_channels]\n",
    "\n",
    "\n",
    "    return X\n",
    "\n",
    "def get_train_data(data_root_path):\n",
    "    \"\"\"\n",
    "    Return X and y\n",
    "    \"\"\"\n",
    "    train_data_path = data_root_path + 'train'\n",
    "    id2label, label2id = get_label_mapping(data_root_path+'labels.txt')\n",
    "    print(label2id)\n",
    "    X = get_images(train_data_path)\n",
    "    y = get_labels(train_data_path, label2id)\n",
    "    return X, y\n",
    "\n",
    "def save_predictions(filename, y):\n",
    "    \"\"\"\n",
    "    Dumps y into .npy file\n",
    "    \"\"\"\n",
    "    np.save(filename, y)\n",
    "    \n",
    "def flip_images_lr(images): \n",
    "    \n",
    "    flipped_images = map(lambda image: np.fliplr(image), images)\n",
    "    flipped_images = np.array(flipped_images)\n",
    "    \n",
    "    return flipped_images\n",
    "\n",
    "#rotates by an angle [-15,15]\n",
    "def rotate_images(images):\n",
    "    \n",
    "    num_images = images.shape[0]\n",
    "    ow,oh = images.shape[1], images.shape[2]\n",
    "\n",
    "    #compute random rotation angles1\n",
    "    rotation_angles = np.random.uniform(-15,15,size=(num_images,))\n",
    "\n",
    "    #rotate the images, preserves size\n",
    "    rotated_images = map(lambda (i,image): scipy.misc.imrotate(image, rotation_angles[i]), enumerate(images))\n",
    "    rotated_images = np.array(rotated_images)\n",
    "\n",
    "    # #resize the images to the original size\n",
    "    # rotated_images = map(lambda image: scipy.misc.imresize(image, (ow, oh)), rotated_images)\n",
    "    # rotated_images = np.array(rotated_images)\n",
    "    return rotated_images\n",
    "\n",
    "\n",
    "#crops 28 X 28 portion of the image and then resizes it to the original size\n",
    "def random_crop_resize_images(images):\n",
    "    ow,oh = images.shape[1],images.shape[2]\n",
    "    num_images = images.shape[0]\n",
    "    sx = np.random.randint(0, 5, size=(num_images, ))\n",
    "    sy = np.random.randint(0, 5, size=(num_images, ))\n",
    "\n",
    "    cropped_resized_images = map(lambda (i,image): image[sx[i]:sx[i]+28, sy[i]:sy[i]+28, :], enumerate(images))\n",
    "    cropped_resized_images = map(lambda image: scipy.misc.imresize(image, (ow, oh)), cropped_resized_images)\n",
    "\n",
    "    cropped_resized_images = np.array(cropped_resized_images)\n",
    "    return cropped_resized_images\n",
    "\n",
    "\n",
    "def add2end(X, y, images, label):\n",
    "    \n",
    "    #add the images to X\n",
    "    X = np.concatenate((X,images), axis = 0)\n",
    "    \n",
    "    #add the labels to y\n",
    "    num_images = images.shape[0]\n",
    "    labels =  np.array([label] * num_images)\n",
    "    y = np.concatenate((y,labels))\n",
    "    \n",
    "    return (X,y)\n",
    "    \n",
    "#txfms - list of strings that state what kind of transformations to use for images in X\n",
    "# 1. fliplr - flip images from left to right\n",
    "# 2. rotate - rotate the images by a random angle in [-15,15]\n",
    "# 3.  crop&resize - crops a random 28X28 portion and resizes it to 32X32\n",
    "\n",
    "#      frac - fraction of images in a clas to be used for transformation. Lies in [0,1]\n",
    "#           - the same fraction is used for all the classes to avoid bias against any specific class\n",
    "def augment(X, y, txfms, frac):\n",
    "    #(batch_size, 32, 32, 3)\n",
    "    all_labels = np.unique(y)\n",
    "    for label in all_labels: \n",
    "        \n",
    "        image_indices_with_this_label = (y == label)\n",
    "        num_images = np.sum(image_indices_with_this_label)\n",
    "        \n",
    "        #selects fraction `frac` out of all the images with this class label\n",
    "        num_images = int(num_images * frac)\n",
    "        image_indices_with_this_label = np.random.randint(0, num_images, size=(num_images, ))\n",
    "        images_with_this_label = X[image_indices_with_this_label, :, :, :]\n",
    "        \n",
    "        \n",
    "        \n",
    "        if \"fliplr\" in txfms: \n",
    "            \n",
    "            #flips the given images and adds them to the end of the data set given\n",
    "            flipped_images = flip_images_lr(images_with_this_label)\n",
    "            (X, y) = add2end(X, y, flipped_images, label)\n",
    "\n",
    "\n",
    "        #rotates the given images by [-15,15]\n",
    "        if \"rotate\" in txfms:\n",
    "\n",
    "            rotated_images = rotate_images(images_with_this_label)\n",
    "            (X, y) = add2end(X, y, rotated_images, label)\n",
    "\n",
    "        #crops and resizes the image to original size\n",
    "        if \"crop&resize\" in txfms: \n",
    "            cropped_resized_images = random_crop_resize_images(images_with_this_label)\n",
    "            (X, y) = add2end(X, y, cropped_resized_images, label)\n",
    "    \n",
    "    return (X,y)\n",
    "def get_batch(X, y, batch_size,list_,counter):\n",
    "    \"\"\"\n",
    "    Return minibatch of samples and labels\n",
    "\n",
    "    :param X, y: samples and corresponding labels\n",
    "    :parma batch_size: minibatch size\n",
    "    :returns: (tuple) X_batch, y_batch\n",
    "    \"\"\"\n",
    "    idx = list_[counter:counter+batch_size]\n",
    "    X_batch = X[idx,:,:,:]\n",
    "    y_batch = y[idx]\n",
    "    #X_batch = augment(X_batch)\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'horse': 7, 'automobile': 1, 'deer': 4, 'dog': 5, 'frog': 6, 'cat': 3, 'truck': 9, 'ship': 8, 'airplane': 0, 'bird': 2}\n",
      "Loaded 10000/50000\n",
      "Loaded 20000/50000\n",
      "Loaded 30000/50000\n",
      "Loaded 40000/50000\n",
      "Loaded 50000/50000\n",
      "Loaded 10000/10000\n",
      "Data loading done\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_root_path = 'cifar10-hw1/'\n",
    "X_train, y_train = get_train_data(data_root_path) # this may take a few minutes\n",
    "X_test = get_images(data_root_path + 'test')\n",
    "print('Data loading done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of samples per class = 5000\n",
    "#number of samples used per transformation per class = frac * 5000\n",
    "#number of samples per transformation = 5000 * frac * 10\n",
    "#number of samples over n transformations = 5000 * frac  * 10 * n\n",
    "#control frac to control number of auxiliary samples generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000,)\n",
      "(10000, 32, 32, 3)\n",
      "(500, 32, 32, 3)\n",
      "(500, 32, 32, 3)\n",
      "(500, 32, 32, 3)\n",
      "(500, 32, 32, 3)"
     ]
    }
   ],
   "source": [
    "print \"Data shapes before augmentation\"\n",
    "print X_train.shape\n",
    "print y_train.shape\n",
    "print X_test.shape\n",
    "\n",
    "\n",
    "#data augmentation\n",
    "print \"Data shapes after augmentation - \"\n",
    "txfms = [\"fliplr\",\"rotate\",\"crop&resize\"]\n",
    "X_train, y_train = augment(X_train, y_train, txfms, 0.1)\n",
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6a7ecb4f940e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0morig_train_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msplit_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtxfms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"fliplr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0morig_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_train_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0morig_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_train_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_train_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxfms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "iters_max=20000\n",
    "batch_size=100\n",
    "split_ratio = 0.9\n",
    "lr_ = 0.01\n",
    "orig_full = range(len(y_train))\n",
    "np.random.shuffle(orig_full)\n",
    "split_idx = int((len(orig_full)*split_ratio))\n",
    "orig_train = orig_full[:split_idx]\n",
    "orig_val = orig_full[split_idx:]\n",
    "counter = 0\n",
    "train_idx = []\n",
    "\n",
    "\n",
    "#extend the data by epochs\n",
    "epocs = (iters_max*batch_size)/len(orig_train) + 1\n",
    "for i in range(epocs):\n",
    "    np.random.shuffle(orig_train)\n",
    "    train_idx.extend(orig_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv1\n",
    "images = tf.placeholder(tf.float32, shape=[None, 32,32,3])\n",
    "gt = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "lr = tf.placeholder(tf.float32, shape=())\n",
    "with tf.variable_scope('conv1') as scope:\n",
    "    init = tf.truncated_normal_initializer(stddev=1e-2, dtype=tf.float32)\n",
    "    kernel = tf.get_variable('weights', shape=[5, 5, 3, 64], initializer=init, dtype=tf.float32)\n",
    "    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.get_variable('biases', shape=[64], initializer=tf.constant_initializer(0.0), dtype=tf.float32)\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "    \n",
    "# pool1\n",
    "pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                     padding='SAME', name='pool1')\n",
    "norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm1') \n",
    "# conv2\n",
    "with tf.variable_scope('conv2') as scope:\n",
    "    init = tf.truncated_normal_initializer(stddev=1e-2, dtype=tf.float32)\n",
    "    kernel = tf.get_variable('weights', shape=[5, 5, 64, 64], initializer=init, dtype=tf.float32)\n",
    "    conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = tf.get_variable('biases', shape=[64], initializer=tf.constant_initializer(0.0), dtype=tf.float32)\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "    \n",
    "pool2 = tf.nn.max_pool(conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                   padding='SAME', name='pool2')\n",
    "norm2 = tf.nn.lrn(pool2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                    name='norm2') \n",
    "# conv3\n",
    "# with tf.variable_scope('conv3') as scope:\n",
    "#     init = tf.truncated_normal_initializer(stddev=1e-2, dtype=tf.float32)\n",
    "#     kernel = tf.get_variable('weights', shape=[3, 3, 64, 64], initializer=init, dtype=tf.float32)\n",
    "#     conv = tf.nn.conv2d(norm2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "#     biases = tf.get_variable('biases', shape=[64], initializer=tf.constant_initializer(0.0), dtype=tf.float32)\n",
    "#     pre_activation = tf.nn.bias_add(conv, biases)\n",
    "#     conv3 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "    \n",
    "# pool3 = tf.nn.max_pool(conv3, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "#                      padding='SAME', name='pool3')\n",
    "# norm3 = tf.nn.lrn(pool3, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "#                     name='norm3')\n",
    "# Fully connected layer    \n",
    "with tf.variable_scope('FC1') as scope:\n",
    "    reshape = tf.reshape(norm2, [batch_size, -1])\n",
    "    init = tf.truncated_normal_initializer(stddev=1/4096.0, dtype=tf.float32)\n",
    "    weights = tf.get_variable('weights', shape=[4096,10], initializer=init, dtype=tf.float32)\n",
    "    biases = tf.get_variable('biases', shape=[10], initializer=tf.constant_initializer(0.0), dtype=tf.float32)\n",
    "    before_softmax = tf.add(tf.matmul(reshape, weights), biases, name=scope.name)\n",
    "    \n",
    "# Fully connected layer    \n",
    "# with tf.variable_scope('FC2') as scope:\n",
    "#     #reshape = pool2\n",
    "#     reshape = tf.reshape(fc1, [batch_size, -1])\n",
    "#     #dim = reshape.get_shape()[1].value\n",
    "#     #print type(dim),dim\n",
    "#     init = tf.truncated_normal_initializer(stddev=1/128.0, dtype=tf.float32)\n",
    "#     weights = tf.get_variable('weights', shape=[128,10], initializer=init, dtype=tf.float32)\n",
    "#     biases = tf.get_variable('biases', shape=[10], initializer=tf.constant_initializer(0.0), dtype=tf.float32)\n",
    "#     before_softmax = tf.add(tf.matmul(reshape, weights), biases, name=scope.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits = before_softmax, labels = gt)\n",
    "loss = tf.reduce_mean(loss)\n",
    "correct_prediction_df = tf.equal(tf.argmax(before_softmax,1), tf.argmax(gt,1))\n",
    "accuracy_df = tf.reduce_mean(tf.cast(correct_prediction_df, tf.float32))\n",
    "train_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.gradients(yvars,xvars)\n",
    "#tf.summary.histogram('', x)\n",
    "tf.summary.scalar('loss',loss)\n",
    "tf.summary.scalar('train_acc',train_acc)\n",
    "conv1_grad = tf.gradients(loss, [conv1])[0]\n",
    "conv2_grad = tf.gradients(loss, [conv2])[0]\n",
    "#conv3_grad = tf.gradients(loss, [conv3])[0]\n",
    "fc1_grad = tf.gradients(loss, [before_softmax])[0]\n",
    "tf.summary.histogram('conv1_grad',conv1_grad)\n",
    "tf.summary.histogram('conv2_grad',conv2_grad)\n",
    "#tf.summary.histogram('conv3_grad',conv3_grad)\n",
    "tf.summary.histogram('fc1_grad',fc1_grad)\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter('tensorboard/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.30178\n",
      "val accuracy  0.098 train accuracy  0.100222\n",
      "100 2.00834\n",
      "200 1.86968\n",
      "300 1.67093\n",
      "400 1.67595\n",
      "500 1.4489\n",
      "val accuracy  0.4464 train accuracy  0.455978\n",
      "600 1.38446\n",
      "700 1.40534\n",
      "800 1.48703\n",
      "900 1.37012\n",
      "1000 1.38827\n",
      "val accuracy  0.5472 train accuracy  0.564089\n",
      "1100 1.08344\n",
      "1200 1.19016\n",
      "1300 1.24692\n",
      "1400 0.997094\n",
      "1500 0.959781\n",
      "val accuracy  0.5992 train accuracy  0.614378\n",
      "1600 1.13643\n",
      "1700 0.898114\n",
      "1800 0.844686\n",
      "1900 1.08844\n",
      "2000 0.911835\n",
      "val accuracy  0.624 train accuracy  0.6522\n",
      "2100 1.03718\n",
      "2200 1.0438\n",
      "2300 1.16777\n",
      "2400 1.03046\n",
      "2500 1.08923\n",
      "val accuracy  0.642 train accuracy  0.670111\n",
      "2600 1.04379\n",
      "2700 0.786138\n",
      "2800 0.83254\n",
      "2900 0.914248\n",
      "3000 0.945823\n",
      "val accuracy  0.678 train accuracy  0.704711\n",
      "3100 1.02561\n",
      "3200 0.991218\n"
     ]
    }
   ],
   "source": [
    "with  tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for iter in range(iters_max):\n",
    "        X_batch, y_batch = get_batch( X_train, y_train, batch_size,train_idx,counter)\n",
    "        counter += batch_size\n",
    "        y_batch = one_hot(y_batch).transpose((1,0))\n",
    "        #loss.run(feed_dict={images: X_batch, gt: y_batch})\n",
    "        if iter%10000 == 1:\n",
    "            lr_/=10.0\n",
    "        _, loss_npy,summary = sess.run([train_step,loss,merged],feed_dict={images: X_batch, gt: y_batch,lr:lr_})\n",
    "        \n",
    "\n",
    "        if iter%100==0:\n",
    "            print iter, loss_npy\n",
    "        if iter%500==0:\n",
    "            test_counter = 0\n",
    "            train_counter = 0\n",
    "            acc_val  = []\n",
    "            acc_train  = []\n",
    "            while test_counter < len(orig_val):  # check if we need to add +1 or -1 REMOVE this BUG\n",
    "                X_batch, y_batch = get_batch( X_train, y_train, batch_size,orig_val,test_counter)\n",
    "                y_batch = one_hot(y_batch).transpose((1,0))\n",
    "                test_counter+=batch_size\n",
    "                acc_val.append(sess.run([accuracy_df],feed_dict={images: X_batch, gt: y_batch,lr:lr_}))\n",
    "            while train_counter < len(orig_train):  # check if we need to add +1 or -1 REMOVE this BUG\n",
    "                X_batch, y_batch = get_batch( X_train, y_train, batch_size,orig_train,train_counter)\n",
    "                y_batch = one_hot(y_batch).transpose((1,0))\n",
    "                train_counter+=batch_size\n",
    "                acc_train.append(sess.run([accuracy_df],feed_dict={images: X_batch, gt: y_batch, lr:lr_}))\n",
    "            print 'val accuracy ', np.mean(np.asarray(acc_val)),'train accuracy ', np.mean(np.asarray(acc_train))\n",
    "            train_acc = np.mean(np.asarray(acc_train))\n",
    "        train_writer.add_summary(summary, iter)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
